# Local AI Agent with Python

Building a local AI agent using **Ollama**, **LangChain**, and **RAG (Retrieval-Augmented Generation)** - following the Tech with Tim tutorial.

## ğŸ“š Learning Source

**YouTube Tutorial:** [How to Build a Local AI Agent With Python (Ollama, LangChain & RAG)](https://www.youtube.com/watch?v=E4l91XKQSgw&t=483s)  
**Channel:** Tech with Tim  
**Date:** February 7, 2026  
**Status:** âœ… **COMPLETED**

---

## ğŸ¯ Learning Objectives

- [x] Understand the fundamentals of AI agents
- [x] Learn to work with **Ollama** for local LLM deployment
- [x] Master **LangChain** framework for agent development
- [x] Implement **RAG (Retrieval-Augmented Generation)** patterns
- [x] Build a fully functional local AI agent from scratch

---

## ğŸ› ï¸ Technologies & Tools

### Core Stack
- **Python** - Primary programming language
- **Ollama** - Local LLM runtime (run models locally without API costs)
- **LangChain** - Framework for building LLM applications
- **RAG** - Retrieval-Augmented Generation for context-aware responses

### Key Concepts to Learn
- Agent architecture and design patterns
- Vector databases and embeddings
- Prompt engineering
- Memory and context management
- Tool/function calling with agents

---

## ğŸ“‹ Prerequisites

### Required
- âœ… Python 3.12 installed (Note: Python 3.14 has compatibility issues with ChromaDB)
- âœ… Basic Python knowledge
- âœ… Ollama installed

### Installed Dependencies
- `langchain` - LangChain framework
- `langchain-core` - Core LangChain functionality
- `langchain-ollama` - Ollama integration for LangChain
- `langchain-chroma` - ChromaDB integration for LangChain
- `pandas` - Data manipulation library

---

## ğŸš€ Setup Instructions

### 1. Install Ollama
```bash
# Download and install from: https://ollama.ai
# Verify installation
ollama --version
```

### 2. Pull Required Models
```bash
# Main LLM for responses
ollama pull llama3.2

# Embedding model for RAG
ollama pull mxbai-embed-large
```

### 3. Set Up Python Environment
```bash
# Create virtual environment with Python 3.12
uv venv --python 3.12

# Activate virtual environment (Windows)
.venv\Scripts\activate

# Install dependencies
uv pip install -r requirements.txt
```

### 4. Run the Application
```bash
# Run the agent
uv run main.py

# Or with activated venv
python main.py
```

---

## ğŸ“ Project Structure

```
2_Local_AI_Agent-OLLAMA/
â”œâ”€â”€ README.md                                  # Project documentation
â”œâ”€â”€ notes.md                                   # Detailed learning notes
â”œâ”€â”€ requirements.txt                           # Python dependencies
â”œâ”€â”€ pyproject.toml                            # Project configuration
â”œâ”€â”€ .python-version                           # Python version (3.12)
â”œâ”€â”€ uv.lock                                   # UV lock file
â”œâ”€â”€ main.py                                   # Main application with user interaction
â”œâ”€â”€ vector.py                                 # RAG implementation (embeddings, vector store)
â”œâ”€â”€ realistic_restaurant_reviews.csv          # Sample data
â”œâ”€â”€ chroma_langchain_db/                      # ChromaDB vector database (auto-created)
â””â”€â”€ .venv/                                    # Virtual environment
```

---

## ğŸ“ Learning Notes

### What I Built
A **local AI agent** that:
- Uses **Ollama** to run LLMs locally (llama3.2)
- Implements **RAG (Retrieval-Augmented Generation)** with ChromaDB
- Loads restaurant reviews from CSV
- Creates embeddings with `mxbai-embed-large`
- Retrieves relevant reviews based on questions
- Generates contextual responses using LangChain

### Key Concepts Learned
- **LangChain chains** - Using the pipe operator (`|`)
- **Prompt templates** - Dynamic prompt construction
- **RAG architecture** - Retrieval + Augmented + Generation
- **Vector databases** - ChromaDB for similarity search
- **pyproject.toml** - Modern Python project configuration
- **Python version compatibility** - 3.14 vs 3.12 issues

ğŸ“š **Detailed notes:** See [notes.md](./notes.md) for comprehensive documentation of concepts, errors, and solutions.

---

## ğŸš§ Current Progress

- [x] Created project structure
- [x] Installed Ollama
- [x] Downloaded llama3.2 and mxbai-embed-large models
- [x] Installed LangChain and dependencies
- [x] Completed tutorial
- [x] Built RAG-powered chatbot
- [x] Implemented vector database with ChromaDB
- [x] Created comprehensive learning notes

---

## ï¿½ Resources & References

### Official Documentation
- [Ollama Documentation](https://ollama.ai/docs)
- [LangChain Documentation](https://python.langchain.com/)
- [LangChain RAG Guide](https://python.langchain.com/docs/use_cases/question_answering/)
- [ChromaDB Documentation](https://docs.trychroma.com/)

### Additional Learning
- [LangChain GitHub](https://github.com/langchain-ai/langchain)
- [Ollama Models Library](https://ollama.ai/library)
- [UV Package Manager](https://github.com/astral-sh/uv)

---

## ğŸ’¡ Next Steps & Project Ideas

Now that the tutorial is complete, potential projects to build:
1. **Personal document Q&A system** - RAG with your own PDFs/notes
2. **Code documentation assistant** - Analyze and explain codebases
3. **Research paper analyzer** - Summarize academic papers
4. **Custom knowledge base chatbot** - Build domain-specific agents
5. **Multi-document comparison tool** - Compare and contrast documents

### Future Learning Topics
- LangChain agents with tool calling
- LangGraph for complex workflows
- Fine-tuning local models
- Building custom embeddings
- Advanced prompt engineering

---

## ï¿½ Issues & Solutions

See [notes.md](./notes.md) for detailed documentation of all errors encountered and their solutions, including:
- Missing `langchain-core` dependency
- Python 3.14 compatibility issues with ChromaDB
- Typos in imports and method names
- UV virtual environment recreation issues

---

**Tutorial Completed! ğŸ‰**  
For detailed learning notes, code explanations, and troubleshooting guide, see [notes.md](./notes.md)
